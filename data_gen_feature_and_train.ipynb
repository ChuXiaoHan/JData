{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle #pickle序列化对象并保存到磁盘中，并在需要的时候读取出来\n",
    "import os\n",
    "import re\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open(\"clean_data_without_no_buy.pkl\", \"rb\") as f:\n",
    "        df_user, df_sku, df_action = pickle.load(f)\n",
    "    return df_user, df_sku, df_action\n",
    "df_user, df_sku, df_action = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取从某个时间段内的总的用户行为特征\n",
    "def get_user_action_feature_from_to(start_time, end_time, df_action):\n",
    "    df_user_action = df_action.loc[(df_action.loc[:, \"time\"] >= start_time) & (df_action.loc[:, \"time\"] < end_time)]\n",
    "    df_user_action = df_user_action.loc[:, [\"user_id\", \"type\", \"time\"]]\n",
    "#     print(df_user_action.head())\n",
    "    df_user_action_type_cnt = df_user_action.groupby([\"user_id\", \"type\"]).count().reset_index()\n",
    "    df_user_action_type_cnt.rename(columns={\"time\":\"cnt\"}, inplace=True)\n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 1) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 2) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 3) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"buy_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 4) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 5) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 6) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    \n",
    "    df_user_action_type_cnt.pop(\"type\")\n",
    "    df_user_action_type_cnt.pop(\"cnt\")\n",
    "    df_user_action_type_cnt = df_user_action_type_cnt.groupby(\"user_id\").sum().reset_index()\n",
    "    \n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    eps = 10**(-6)\n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"browse_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"addcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"delcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"follow_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"click_cnt\"] + eps)\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = (df_user_action_type_cnt.loc[:, \"browse_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = (df_user_action_type_cnt.loc[:, \"addcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = (df_user_action_type_cnt.loc[:, \"delcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = (df_user_action_type_cnt.loc[:, \"follow_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = (df_user_action_type_cnt.loc[:, \"click_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "                                              \n",
    "    df_user_action_feature = df_user_action_type_cnt\n",
    "    return df_user_action_feature\n",
    "    \n",
    "# get_user_action_feature_from_to(pd.to_datetime(\"2016-02-01\"), pd.to_datetime(\"2016-04-18\"), df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取某时间段内用户针对某类别cate商品的行为特征\n",
    "def get_user_cate_feature_from_to(start_time, end_time, df_action, df_sku):\n",
    "    df_user_action = df_action.loc[(df_action.loc[:, \"time\"] >= start_time) & (df_action.loc[:, \"time\"] < end_time)]\n",
    "    df_user_action = df_user_action.loc[:, [\"user_id\", \"sku_id\", \"type\", \"time\"]]\n",
    "    df_user_action = pd.merge(df_user_action, df_sku.loc[:, [\"sku_id\", \"cate\"]], how=\"left\", on=\"sku_id\")\n",
    "    df_user_action.pop(\"sku_id\")\n",
    "    df_user_action_type_cnt = df_user_action.groupby([\"user_id\", \"cate\", \"type\"]).count().reset_index()\n",
    "    df_user_action_type_cnt.rename(columns={\"time\":\"cnt\"}, inplace=True)\n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 1) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 2) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 3) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"buy_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 4) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 5) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 6) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    \n",
    "    df_user_action_type_cnt.pop(\"type\")\n",
    "    df_user_action_type_cnt.pop(\"cnt\")\n",
    "    df_user_action_type_cnt = df_user_action_type_cnt.groupby([\"user_id\", \"cate\"]).sum().reset_index()\n",
    "    \n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    eps = 10**(-6)\n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"browse_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"addcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"delcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"follow_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"click_cnt\"] + eps)\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = (df_user_action_type_cnt.loc[:, \"browse_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = (df_user_action_type_cnt.loc[:, \"addcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = (df_user_action_type_cnt.loc[:, \"delcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = (df_user_action_type_cnt.loc[:, \"follow_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = (df_user_action_type_cnt.loc[:, \"click_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "                                              \n",
    "    df_user_cate_feature = df_user_action_type_cnt\n",
    "    return df_user_cate_feature\n",
    "    \n",
    "# get_user_cate_feature_from_to(pd.to_datetime(\"2016-03-01\"), pd.to_datetime(\"2016-03-30\"), df_action, df_sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取某时间段内用户针对某品牌brand商品的行为特征\n",
    "def get_user_brand_feature_from_to(start_time, end_time, df_action, df_sku):\n",
    "    df_user_action = df_action.loc[(df_action.loc[:, \"time\"] >= start_time) & (df_action.loc[:, \"time\"] < end_time)]\n",
    "    df_user_action = df_user_action.loc[:, [\"user_id\", \"sku_id\", \"type\", \"time\"]]\n",
    "    df_user_action = pd.merge(df_user_action, df_sku.loc[:, [\"sku_id\", \"brand\"]], how=\"left\", on=\"sku_id\")\n",
    "    df_user_action.pop(\"sku_id\")\n",
    "    df_user_action_type_cnt = df_user_action.groupby([\"user_id\", \"brand\", \"type\"]).count().reset_index()\n",
    "    df_user_action_type_cnt.rename(columns={\"time\":\"cnt\"}, inplace=True)\n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 1) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 2) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 3) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"buy_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 4) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 5) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 6) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    \n",
    "    df_user_action_type_cnt.pop(\"type\")\n",
    "    df_user_action_type_cnt.pop(\"cnt\")\n",
    "    df_user_action_type_cnt = df_user_action_type_cnt.groupby([\"user_id\", \"brand\"]).sum().reset_index()\n",
    "    \n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    eps = 10**(-6)\n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"browse_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"addcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"delcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"follow_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"click_cnt\"] + eps)\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = (df_user_action_type_cnt.loc[:, \"browse_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = (df_user_action_type_cnt.loc[:, \"addcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = (df_user_action_type_cnt.loc[:, \"delcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = (df_user_action_type_cnt.loc[:, \"follow_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = (df_user_action_type_cnt.loc[:, \"click_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "                                              \n",
    "    df_user_brand_feature = df_user_action_type_cnt\n",
    "    return df_user_brand_feature\n",
    "    \n",
    "# get_user_brand_feature_from_to(pd.to_datetime(\"2016-02-01\"), pd.to_datetime(\"2016-05-02\"), df_action, df_sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取某时间段内用户针对某商品sku_id的行为特征\n",
    "def get_user_sku_feature_from_to(start_time, end_time, df_action):\n",
    "    df_user_action = df_action.loc[(df_action.loc[:, \"time\"] >= start_time) & (df_action.loc[:, \"time\"] < end_time)]\n",
    "    df_user_action = df_user_action.loc[:, [\"user_id\", \"sku_id\", \"type\", \"time\"]]\n",
    "    df_user_action_type_cnt = df_user_action.groupby([\"user_id\", \"sku_id\", \"type\"]).count().reset_index()\n",
    "    df_user_action_type_cnt.rename(columns={\"time\":\"cnt\"}, inplace=True)\n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 1) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 2) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 3) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"buy_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 4) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 5) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 6) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    \n",
    "    df_user_action_type_cnt.pop(\"type\")\n",
    "    df_user_action_type_cnt.pop(\"cnt\")\n",
    "    df_user_action_type_cnt = df_user_action_type_cnt.groupby([\"user_id\", \"sku_id\"]).sum().reset_index()\n",
    "    \n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    eps = 10**(-6)\n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"browse_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"addcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"delcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"follow_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"click_cnt\"] + eps)\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = (df_user_action_type_cnt.loc[:, \"browse_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = (df_user_action_type_cnt.loc[:, \"addcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = (df_user_action_type_cnt.loc[:, \"delcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = (df_user_action_type_cnt.loc[:, \"follow_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = (df_user_action_type_cnt.loc[:, \"click_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "                                              \n",
    "    df_user_sku_feature = df_user_action_type_cnt\n",
    "    return df_user_sku_feature\n",
    "    \n",
    "# get_user_sku_feature_from_to(pd.to_datetime(\"2016-03-01\"), pd.to_datetime(\"2016-03-02\"), df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取商品某时间段内被用户行为的特征\n",
    "def get_sku_action_feature_from_to(start_time, end_time, df_action):\n",
    "    df_user_action = df_action.loc[(df_action.loc[:, \"time\"] >= start_time) & (df_action.loc[:, \"time\"] < end_time)]\n",
    "    df_user_action = df_user_action.loc[:, [\"sku_id\", \"type\", \"time\"]]\n",
    "    df_user_action_type_cnt = df_user_action.groupby([\"sku_id\", \"type\"]).count().reset_index()\n",
    "    df_user_action_type_cnt.rename(columns={\"time\":\"cnt\"}, inplace=True)\n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 1) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 2) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 3) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"buy_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 4) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 5) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_cnt\"] = ((df_user_action_type_cnt.loc[:, \"type\"] == 6) \\\n",
    "                                            * df_user_action_type_cnt.loc[:, \"cnt\"]).astype(np.float32)\n",
    "    \n",
    "    df_user_action_type_cnt.pop(\"type\")\n",
    "    df_user_action_type_cnt.pop(\"cnt\")\n",
    "    df_user_action_type_cnt = df_user_action_type_cnt.groupby(\"sku_id\").sum().reset_index()\n",
    "    \n",
    "#     print(df_user_action_type_cnt.head())\n",
    "    eps = 10**(-6)\n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"browse_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"addcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"delcart_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"follow_cnt\"] + eps)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = df_user_action_type_cnt.loc[:, \"buy_cnt\"] \\\n",
    "                                                    / (df_user_action_type_cnt.loc[:, \"click_cnt\"] + eps)\n",
    "    \n",
    "    df_user_action_type_cnt.loc[:, \"browse_rate\"] = (df_user_action_type_cnt.loc[:, \"browse_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"addcart_rate\"] = (df_user_action_type_cnt.loc[:, \"addcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"delcart_rate\"] = (df_user_action_type_cnt.loc[:, \"delcart_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"follow_rate\"] = (df_user_action_type_cnt.loc[:, \"follow_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "    df_user_action_type_cnt.loc[:, \"click_rate\"] = (df_user_action_type_cnt.loc[:, \"click_rate\"] \\\n",
    "                                            .apply(lambda x : 1.0 if x>0.9999 else x)).astype(np.float32)\n",
    "                                              \n",
    "    df_sku_action_feature = df_user_action_type_cnt\n",
    "    return df_sku_action_feature\n",
    "    \n",
    "# get_sku_action_feature_from_to(pd.to_datetime(\"2016-03-01\"), pd.to_datetime(\"2016-03-30\"), df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一个辅助函数，用来命名多个可能重名的属性特征\n",
    "def rename_columns_with_day(df, fixstr):\n",
    "    column_dict = {\"browse_cnt\" : \"browse_cnt\"+fixstr, \\\n",
    "                  \"addcart_cnt\" : \"addcart_cnt\"+fixstr, \\\n",
    "                  \"delcart_cnt\" : \"delcart_cnt\"+fixstr, \\\n",
    "                  \"buy_cnt\" : \"buy_cnt\"+fixstr, \\\n",
    "                  \"follow_cnt\" : \"follow_cnt\"+fixstr, \\\n",
    "                  \"click_cnt\" : \"click_cnt\"+fixstr, \\\n",
    "                  \"browse_rate\" : \"browse_rate\"+fixstr, \\\n",
    "                  \"addcart_rate\" : \"addcart_rate\"+fixstr, \\\n",
    "                  \"delcart_rate\" : \"delcart_rate\"+fixstr, \\\n",
    "                  \"follow_rate\" : \"follow_rate\"+fixstr, \\\n",
    "                  \"click_rate\" : \"click_rate\"+fixstr}\n",
    "    df.rename(columns=column_dict, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取用户的固有特征（基本特征，整个时间段的行为特征）\n",
    "def get_user_constant_feature(df_user, df_sku, df_action):\n",
    "    \n",
    "    df_user_base_feature = df_user.copy()\n",
    "    \n",
    "    start_time = pd.to_datetime(\"2016-01-01\")\n",
    "    end_time = pd.to_datetime(\"2016-06-07\")\n",
    "    df_user_action_feature_all_days = get_user_action_feature_from_to(start_time, end_time, df_action)\n",
    "    df_user_cate_feature_all_days = get_user_cate_feature_from_to(start_time, end_time, df_action, df_sku)\n",
    "    df_user_brand_feature_all_days = get_user_brand_feature_from_to(start_time, end_time, df_action, df_sku)\n",
    "    df_user_sku_feature_all_days = get_user_sku_feature_from_to(start_time, end_time, df_action)\n",
    "    \n",
    "    df_user_action_feature_all_days = rename_columns_with_day(df_user_action_feature_all_days, \"_user_all\")\n",
    "    df_user_cate_feature_all_days = rename_columns_with_day(df_user_cate_feature_all_days, \"_user_cate_all\")\n",
    "    df_user_brand_feature_all_days = rename_columns_with_day(df_user_brand_feature_all_days, \"_user_brand_all\")\n",
    "    df_user_sku_feature_all_days = rename_columns_with_day(df_user_sku_feature_all_days, \"_user_sku_all\")\n",
    "    \n",
    "    list_df_user_constant_feature = [df_user_base_feature, \\\n",
    "                                    df_user_action_feature_all_days, \\\n",
    "                                    df_user_cate_feature_all_days, \\\n",
    "                                    df_user_brand_feature_all_days, \\\n",
    "                                    df_user_sku_feature_all_days]\n",
    "    \n",
    "    return list_df_user_constant_feature\n",
    "\n",
    "list_df_user_constant_feature = get_user_constant_feature(df_user, df_sku, df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取商品的固有特征（基本特征，整个时间段的被用户行为特征）\n",
    "def get_sku_constant_feature(df_sku, df_action):\n",
    "    df_sku_base_feature = df_sku\n",
    "    df_sku_action_feature_all_days = get_sku_action_feature_from_to(pd.to_datetime(\"2016-01-01\"), pd.to_datetime(\"2016-06-07\"), df_action)\n",
    "    df_sku_action_feature_all_days = rename_columns_with_day(df_sku_action_feature_all_days, \"_sku_all\")\n",
    "    list_df_sku_constant_feature = [df_sku_base_feature, df_sku_action_feature_all_days]\n",
    "    return list_df_sku_constant_feature\n",
    "list_df_sku_constant_feature = get_sku_constant_feature(df_sku, df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取一个时间窗口的购买前多个不同时间段的特征    \n",
    "def get_feature_of_one_window(start_time, end_time, df_action, df_sku):\n",
    "    if end_time - start_time < datetime.timedelta(days=30):\n",
    "#     if end_time - start_time < datetime.timedelta(days=30):\n",
    "        raise(\"时间区间太短啦！\")\n",
    "    #统计时间段特征使用 [1, 2, 3, 5, 7, 10, 15, 20, 30] 天的\n",
    "    before_days = [1, 2, 3, 5, 7, 10, 15, 20, 30]\n",
    "#     before_days = [1, 2]\n",
    "    \n",
    "    list_df_user_action_feature_before_days = [] #用户对所有商品行为特征\n",
    "    list_df_user_cate_feature_before_days = [] #用户对不同类商品别行为特征\n",
    "    list_df_user_brand_feature_before_days = [] #用户对不同品牌商品行为特征\n",
    "    list_df_user_sku_feature_before_days = [] #用户对不同商品行为特征\n",
    "    list_df_sku_action_feature_before_days = [] #商品被所有用户行为的特征\n",
    "    \n",
    "    for day in before_days:\n",
    "        start_before_day = end_time - datetime.timedelta(days=day)\n",
    "        \n",
    "        df_user_action_feature = get_user_action_feature_from_to(start_before_day, end_time, df_action)\n",
    "        df_user_cate_feature = get_user_cate_feature_from_to(start_before_day, end_time, df_action, df_sku)\n",
    "        df_user_brand_feature = get_user_brand_feature_from_to(start_before_day, end_time, df_action, df_sku)\n",
    "        df_user_sku_feature = get_user_sku_feature_from_to(start_before_day, end_time, df_action)\n",
    "        df_sku_action_feature = get_sku_action_feature_from_to(start_before_day, end_time, df_action)\n",
    "        \n",
    "        df_user_action_feature = rename_columns_with_day(df_user_action_feature, \"_user_\"+str(day))\n",
    "        df_user_cate_feature = rename_columns_with_day(df_user_cate_feature, \"_user_cate_\"+str(day))\n",
    "        df_user_brand_feature = rename_columns_with_day(df_user_brand_feature, \"_user_brand_\"+str(day))\n",
    "        df_user_sku_feature = rename_columns_with_day(df_user_sku_feature, \"_user_sku_\"+str(day))\n",
    "        df_sku_action_feature = rename_columns_with_day(df_sku_action_feature, \"_sku_\"+str(day))\n",
    "        \n",
    "        \n",
    "        list_df_user_action_feature_before_days.append(df_user_action_feature)\n",
    "        list_df_user_cate_feature_before_days.append(df_user_cate_feature)\n",
    "        list_df_user_brand_feature_before_days.append(df_user_brand_feature)\n",
    "        list_df_user_sku_feature_before_days.append(df_user_sku_feature)\n",
    "        list_df_sku_action_feature_before_days.append(df_sku_action_feature)\n",
    "    \n",
    "    \n",
    "    return list_df_user_action_feature_before_days, \\\n",
    "            list_df_user_cate_feature_before_days, \\\n",
    "            list_df_user_brand_feature_before_days, \\\n",
    "            list_df_user_sku_feature_before_days, \\\n",
    "            list_df_sku_action_feature_before_days\n",
    "# lists_features_one_window = get_feature_of_one_window(pd.to_datetime(\"2016-02-05\"), pd.to_datetime(\"2016-02-10\"), df_action, df_sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取用户在某时间段内是否购买的标签，令 end_time - start_time = 5，用来生成数据集label\n",
    "def get_user_sku_buy_label_from_to(start_time, end_time, df_action):\n",
    "    print(start_time, end_time)\n",
    "    df_user_sku_feature = get_user_sku_feature_from_to(start_time, end_time, df_action)\n",
    "    df_user_sku_buy_label = df_user_sku_feature.loc[:, [\"user_id\", \"sku_id\", \"buy_cnt\"]]\n",
    "    df_user_sku_buy_label.loc[:, \"buy_label\"] = df_user_sku_buy_label.loc[:, \"buy_cnt\"] \\\n",
    "                                                .apply(lambda x : True if x>=1 else False) #catboost使用1和-1做二分类标签\n",
    "    df_user_sku_buy_label.pop(\"buy_cnt\")\n",
    "    return df_user_sku_buy_label\n",
    "\n",
    "# df_user_sku_buy_label = get_user_sku_buy_label_from_to(pd.to_datetime(\"2016-02-05\"), pd.to_datetime(\"2016-02-06\"), df_action)\n",
    "# print(df_user_sku_buy_label.loc[df_user_sku_buy_label.loc[:, \"buy_label\"] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dataset(df_dataset):\n",
    "    column_list = df_dataset.columns.values.tolist()\n",
    "#     print(column_list)\n",
    "    df_dataset.fillna(0, inplace=True)\n",
    "\n",
    "    for column in column_list:\n",
    "        if re.match(r\"user_id[0-9]\", column) or re.match(r\"sku_id[0-9]\", column) is not None:\n",
    "            df_dataset.pop(column)\n",
    "\n",
    "        if re.match(r\"cate[0-9]\", column) or re.match(r\"brand[0-9]\", column) is not None:\n",
    "            df_dataset.pop(column)\n",
    "\n",
    "#         if re.match(r\".*_cnt.*\", column) is not None:\n",
    "#             df_dataset.loc[:, column] = df_dataset.loc[:, column].astype(np.int16)\n",
    "\n",
    "#         if re.match(r\".*_rate.*\", column) is not None:\n",
    "#             df_dataset.loc[:, column] = df_dataset.loc[:, column].astype(np.float16)\n",
    "\n",
    "    return df_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取一个时间窗口的训练集\n",
    "def get_dataset_of_one_window(start_time, end_time, \\\n",
    "                                    df_user, df_sku, df_action, \\\n",
    "                                    list_df_user_constant_feature, list_df_sku_constant_feature):\n",
    "    list_df_user_action_feature_before_days, \\\n",
    "    list_df_user_cate_feature_before_days, \\\n",
    "    list_df_user_brand_feature_before_days, \\\n",
    "    list_df_user_sku_feature_before_days, \\\n",
    "    list_df_sku_action_feature_before_days = get_feature_of_one_window(start_time, end_time, df_action, df_sku)\n",
    "    \n",
    "    df_user_sku_buy_label = get_user_sku_buy_label_from_to(end_time, end_time + datetime.timedelta(days=5), df_action)\n",
    "    \n",
    "    df_dataset = list_df_user_sku_feature_before_days[-1].loc[:, [\"user_id\", \"sku_id\"]].drop_duplicates()\n",
    "    print(\"len_df_dataset: \", len(df_dataset))\n",
    "    df_dataset = pd.merge(df_dataset, df_sku.loc[:, [\"sku_id\", \"cate\", \"brand\"]], how=\"left\", on=\"sku_id\")\n",
    "    \n",
    "    suffix_y = 1\n",
    "    for df_user_constant_feature in list_df_user_constant_feature:\n",
    "        if \"sku_id\" in df_user_constant_feature.columns.tolist():\n",
    "            df_dataset = pd.merge(df_dataset, df_user_constant_feature, how=\"left\", on=[\"user_id\", \"sku_id\"], suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        elif \"cate\" in df_user_constant_feature.columns.tolist():\n",
    "            df_dataset = pd.merge(df_dataset, df_user_constant_feature, how=\"left\", on=[\"user_id\", \"cate\"], suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        elif \"brand\" in df_user_constant_feature.columns.tolist():\n",
    "            df_dataset = pd.merge(df_dataset, df_user_constant_feature, how=\"left\", on=[\"user_id\", \"brand\"], suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        else:\n",
    "            df_dataset = pd.merge(df_dataset, df_user_constant_feature, how=\"left\", on=\"user_id\", suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        \n",
    "        df_user_constant_feature = None\n",
    "#         print(1)\n",
    "        suffix_y += 1\n",
    "        \n",
    "    for df_sku_constant_feature in list_df_sku_constant_feature:\n",
    "        df_dataset = pd.merge(df_dataset, df_sku_constant_feature, how=\"left\", on=\"sku_id\", suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        df_sku_constant_feature = None\n",
    "#         print(2)\n",
    "        suffix_y += 1\n",
    "        \n",
    "    for df_user_action_feature_before_days in list_df_user_action_feature_before_days:\n",
    "        df_dataset = pd.merge(df_dataset, df_user_action_feature_before_days, how=\"left\", on=\"user_id\", suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        df_user_action_feature_before_days = None\n",
    "#         print(3)\n",
    "        suffix_y += 1\n",
    "        \n",
    "    for df_user_cate_feature_before_days in list_df_user_cate_feature_before_days:\n",
    "        df_dataset = pd.merge(df_dataset, df_user_cate_feature_before_days, how=\"left\", on=[\"user_id\", \"cate\"], suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        df_user_cate_feature_before_days = None\n",
    "#         print(4)\n",
    "        suffix_y += 1\n",
    "        \n",
    "    for df_user_brand_feature_before_days in list_df_user_brand_feature_before_days:\n",
    "        df_dataset = pd.merge(df_dataset, df_user_brand_feature_before_days, how=\"left\", on=[\"user_id\", \"brand\"], suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        df_user_brand_feature_before_days = None\n",
    "#         print(5)\n",
    "        suffix_y += 1\n",
    "        \n",
    "    for df_user_sku_feature_before_days in list_df_user_sku_feature_before_days:\n",
    "        df_dataset = pd.merge(df_dataset, df_user_sku_feature_before_days, how=\"left\", on=[\"user_id\", \"sku_id\"], suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        df_user_sku_feature_before_days = None\n",
    "#         print(6)\n",
    "        suffix_y += 1\n",
    "        \n",
    "    for df_sku_action_feature_before_days in list_df_sku_action_feature_before_days:\n",
    "        df_dataset = pd.merge(df_dataset, df_sku_action_feature_before_days, how=\"left\", on=\"sku_id\", suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "        df_sku_action_feature_before_days = None\n",
    "#         print(7)\n",
    "        suffix_y += 1\n",
    "        \n",
    "    df_dataset = pd.merge(df_dataset, df_user_sku_buy_label, how=\"left\", on=[\"user_id\", \"sku_id\"], suffixes=(\"\", str(suffix_y)), sort=False)\n",
    "    df_dataset.loc[:, \"buy_label\"] = df_dataset.loc[:, \"buy_label\"].apply(lambda x: False if np.isnan(x) else x)\n",
    "    \n",
    "    df_dataset = fix_dataset(df_dataset)\n",
    "    print(\"len_df_dataset: \", len(df_dataset))\n",
    "    return df_dataset\n",
    "\n",
    "# df_dataset = get_dataset_of_one_window(pd.to_datetime(\"2016-02-05\"), pd.to_datetime(\"2016-02-07\"), \\\n",
    "#                                     df_user, df_sku, df_action, \\\n",
    "#                                     list_df_user_constant_feature, list_df_sku_constant_feature)\n",
    "# df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-02 00:00:00 2016-03-07 00:00:00\n",
      "len_df_dataset:  108712\n",
      "len_df_dataset:  108712\n",
      "2016-03-12 00:00:00 2016-03-17 00:00:00\n",
      "len_df_dataset:  181605\n",
      "len_df_dataset:  181605\n",
      "2016-03-22 00:00:00 2016-03-27 00:00:00\n",
      "len_df_dataset:  247687\n",
      "len_df_dataset:  247687\n",
      "2016-04-01 00:00:00 2016-04-06 00:00:00\n",
      "len_df_dataset:  259650\n",
      "len_df_dataset:  259650\n",
      "2016-04-11 00:00:00 2016-04-16 00:00:00\n",
      "len_df_dataset:  254062\n",
      "len_df_dataset:  254062\n"
     ]
    }
   ],
   "source": [
    "#获取数据集\n",
    "def get_dataset(window_size, window_stride, whole_start_time, whole_end_time, \\\n",
    "                df_user, df_sku, df_action, \\\n",
    "                list_df_user_constant_feature, list_df_sku_constant_feature):\n",
    "    df_dataset = pd.DataFrame()\n",
    "    start_time = whole_start_time\n",
    "    end_time = start_time + datetime.timedelta(days=window_size)\n",
    "    while end_time < whole_end_time:\n",
    "        one_window_dataset = get_dataset_of_one_window(start_time, end_time, \\\n",
    "                                    df_user, df_sku, df_action, \\\n",
    "                                    list_df_user_constant_feature, list_df_sku_constant_feature)\n",
    "        \n",
    "        df_dataset = one_window_dataset.append(df_dataset)\n",
    "        \n",
    "        start_time = start_time + datetime.timedelta(days=window_stride)\n",
    "        end_time = start_time + datetime.timedelta(days=window_size)\n",
    "        \n",
    "    return df_dataset\n",
    "\n",
    "df_dataset = get_dataset(30, 10, pd.to_datetime(\"2016-02-01\"), pd.to_datetime(\"2016-04-15\"), \\\n",
    "                         df_user, df_sku, df_action, \\\n",
    "                         list_df_user_constant_feature, list_df_sku_constant_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_dataset(df_dataset):\n",
    "    if not os.path.exists(\"df_dataset.pkl\"):\n",
    "        with open(\"df_dataset.pkl\", \"wb\") as f:\n",
    "            pickle.dump(df_dataset, f)\n",
    "            \n",
    "def load_df_dataset():\n",
    "    with open(\"df_dataset.pkl\", \"rb\") as f:\n",
    "        df_dataset = pickle.load(f)\n",
    "    return df_dataset\n",
    "\n",
    "# save_df_dataset(df_dataset)\n",
    "# df_dataset = load_df_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_dataset(df_dataset, test_size):\n",
    "    train_size = len(df_dataset) - test_size\n",
    "    train_dataset = df_dataset.head(train_size)\n",
    "    test_dataset = df_dataset.tail(test_size)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "df_train_dataset, df_test_dataset = get_train_test_dataset(df_dataset, 254062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6000216\ttotal: 213ms\tremaining: 31.7s\n",
      "1:\tlearn: 0.5200421\ttotal: 416ms\tremaining: 30.8s\n",
      "2:\tlearn: 0.4497099\ttotal: 618ms\tremaining: 30.3s\n",
      "3:\tlearn: 0.3905455\ttotal: 782ms\tremaining: 28.5s\n",
      "4:\tlearn: 0.3042123\ttotal: 961ms\tremaining: 27.9s\n",
      "5:\tlearn: 0.2456926\ttotal: 1.14s\tremaining: 27.4s\n",
      "6:\tlearn: 0.1904799\ttotal: 1.31s\tremaining: 26.7s\n",
      "7:\tlearn: 0.1519922\ttotal: 1.52s\tremaining: 27s\n",
      "8:\tlearn: 0.1192004\ttotal: 1.7s\tremaining: 26.6s\n",
      "9:\tlearn: 0.0932852\ttotal: 1.86s\tremaining: 26.1s\n",
      "10:\tlearn: 0.0738627\ttotal: 2.04s\tremaining: 25.8s\n",
      "11:\tlearn: 0.0591132\ttotal: 2.23s\tremaining: 25.6s\n",
      "12:\tlearn: 0.0467990\ttotal: 2.39s\tremaining: 25.1s\n",
      "13:\tlearn: 0.0379000\ttotal: 2.56s\tremaining: 24.9s\n",
      "14:\tlearn: 0.0312534\ttotal: 2.75s\tremaining: 24.8s\n",
      "15:\tlearn: 0.0258914\ttotal: 2.94s\tremaining: 24.6s\n",
      "16:\tlearn: 0.0213190\ttotal: 3.11s\tremaining: 24.3s\n",
      "17:\tlearn: 0.0178654\ttotal: 3.29s\tremaining: 24.1s\n",
      "18:\tlearn: 0.0152011\ttotal: 3.48s\tremaining: 24s\n",
      "19:\tlearn: 0.0129997\ttotal: 3.65s\tremaining: 23.8s\n",
      "20:\tlearn: 0.0113124\ttotal: 3.84s\tremaining: 23.6s\n",
      "21:\tlearn: 0.0099566\ttotal: 4.02s\tremaining: 23.4s\n",
      "22:\tlearn: 0.0089262\ttotal: 4.22s\tremaining: 23.3s\n",
      "23:\tlearn: 0.0080871\ttotal: 4.42s\tremaining: 23.2s\n",
      "24:\tlearn: 0.0073968\ttotal: 4.58s\tremaining: 22.9s\n",
      "25:\tlearn: 0.0068036\ttotal: 4.76s\tremaining: 22.7s\n",
      "26:\tlearn: 0.0063454\ttotal: 4.92s\tremaining: 22.4s\n",
      "27:\tlearn: 0.0059076\ttotal: 5.09s\tremaining: 22.2s\n",
      "28:\tlearn: 0.0055870\ttotal: 5.26s\tremaining: 21.9s\n",
      "29:\tlearn: 0.0052694\ttotal: 5.43s\tremaining: 21.7s\n",
      "30:\tlearn: 0.0050675\ttotal: 5.59s\tremaining: 21.5s\n",
      "31:\tlearn: 0.0048449\ttotal: 5.76s\tremaining: 21.3s\n",
      "32:\tlearn: 0.0046847\ttotal: 5.93s\tremaining: 21s\n",
      "33:\tlearn: 0.0045611\ttotal: 6.09s\tremaining: 20.8s\n",
      "34:\tlearn: 0.0044212\ttotal: 6.25s\tremaining: 20.5s\n",
      "35:\tlearn: 0.0043022\ttotal: 6.41s\tremaining: 20.3s\n",
      "36:\tlearn: 0.0041692\ttotal: 6.57s\tremaining: 20.1s\n",
      "37:\tlearn: 0.0040642\ttotal: 6.74s\tremaining: 19.9s\n",
      "38:\tlearn: 0.0039647\ttotal: 6.9s\tremaining: 19.6s\n",
      "39:\tlearn: 0.0039037\ttotal: 7.09s\tremaining: 19.5s\n",
      "40:\tlearn: 0.0038393\ttotal: 7.27s\tremaining: 19.3s\n",
      "41:\tlearn: 0.0038047\ttotal: 7.45s\tremaining: 19.2s\n",
      "42:\tlearn: 0.0037563\ttotal: 7.61s\tremaining: 18.9s\n",
      "43:\tlearn: 0.0037088\ttotal: 7.77s\tremaining: 18.7s\n",
      "44:\tlearn: 0.0036604\ttotal: 7.94s\tremaining: 18.5s\n",
      "45:\tlearn: 0.0036211\ttotal: 8.11s\tremaining: 18.3s\n",
      "46:\tlearn: 0.0035850\ttotal: 8.28s\tremaining: 18.1s\n",
      "47:\tlearn: 0.0035552\ttotal: 8.44s\tremaining: 17.9s\n",
      "48:\tlearn: 0.0035383\ttotal: 8.59s\tremaining: 17.7s\n",
      "49:\tlearn: 0.0035063\ttotal: 8.75s\tremaining: 17.5s\n",
      "50:\tlearn: 0.0034766\ttotal: 8.93s\tremaining: 17.3s\n",
      "51:\tlearn: 0.0034508\ttotal: 9.11s\tremaining: 17.2s\n",
      "52:\tlearn: 0.0034454\ttotal: 9.28s\tremaining: 17s\n",
      "53:\tlearn: 0.0034239\ttotal: 9.44s\tremaining: 16.8s\n",
      "54:\tlearn: 0.0034025\ttotal: 9.61s\tremaining: 16.6s\n",
      "55:\tlearn: 0.0033862\ttotal: 9.77s\tremaining: 16.4s\n",
      "56:\tlearn: 0.0033708\ttotal: 9.93s\tremaining: 16.2s\n",
      "57:\tlearn: 0.0033563\ttotal: 10.1s\tremaining: 16s\n",
      "58:\tlearn: 0.0033431\ttotal: 10.3s\tremaining: 15.9s\n",
      "59:\tlearn: 0.0033318\ttotal: 10.4s\tremaining: 15.6s\n",
      "60:\tlearn: 0.0033205\ttotal: 10.6s\tremaining: 15.5s\n",
      "61:\tlearn: 0.0033100\ttotal: 10.8s\tremaining: 15.3s\n",
      "62:\tlearn: 0.0033032\ttotal: 10.9s\tremaining: 15.1s\n",
      "63:\tlearn: 0.0032871\ttotal: 11.1s\tremaining: 14.9s\n",
      "64:\tlearn: 0.0032745\ttotal: 11.3s\tremaining: 14.7s\n",
      "65:\tlearn: 0.0032613\ttotal: 11.4s\tremaining: 14.5s\n",
      "66:\tlearn: 0.0032584\ttotal: 11.6s\tremaining: 14.3s\n",
      "67:\tlearn: 0.0032487\ttotal: 11.7s\tremaining: 14.2s\n",
      "68:\tlearn: 0.0032361\ttotal: 11.9s\tremaining: 14s\n",
      "69:\tlearn: 0.0032315\ttotal: 12.1s\tremaining: 13.8s\n",
      "70:\tlearn: 0.0032189\ttotal: 12.2s\tremaining: 13.6s\n",
      "71:\tlearn: 0.0032145\ttotal: 12.4s\tremaining: 13.4s\n",
      "72:\tlearn: 0.0032143\ttotal: 12.6s\tremaining: 13.3s\n",
      "73:\tlearn: 0.0032080\ttotal: 12.7s\tremaining: 13.1s\n",
      "74:\tlearn: 0.0032016\ttotal: 12.9s\tremaining: 12.9s\n",
      "75:\tlearn: 0.0032003\ttotal: 13.1s\tremaining: 12.7s\n",
      "76:\tlearn: 0.0031953\ttotal: 13.3s\tremaining: 12.6s\n",
      "77:\tlearn: 0.0031872\ttotal: 13.4s\tremaining: 12.4s\n",
      "78:\tlearn: 0.0031797\ttotal: 13.6s\tremaining: 12.2s\n",
      "79:\tlearn: 0.0031779\ttotal: 13.7s\tremaining: 12s\n",
      "80:\tlearn: 0.0031734\ttotal: 13.9s\tremaining: 11.8s\n",
      "81:\tlearn: 0.0031689\ttotal: 14s\tremaining: 11.6s\n",
      "82:\tlearn: 0.0031645\ttotal: 14.2s\tremaining: 11.5s\n",
      "83:\tlearn: 0.0031575\ttotal: 14.4s\tremaining: 11.3s\n",
      "84:\tlearn: 0.0031491\ttotal: 14.5s\tremaining: 11.1s\n",
      "85:\tlearn: 0.0031410\ttotal: 14.7s\tremaining: 10.9s\n",
      "86:\tlearn: 0.0031385\ttotal: 14.9s\tremaining: 10.8s\n",
      "87:\tlearn: 0.0031347\ttotal: 15s\tremaining: 10.6s\n",
      "88:\tlearn: 0.0031321\ttotal: 15.2s\tremaining: 10.4s\n",
      "89:\tlearn: 0.0031245\ttotal: 15.4s\tremaining: 10.2s\n",
      "90:\tlearn: 0.0031196\ttotal: 15.5s\tremaining: 10.1s\n",
      "91:\tlearn: 0.0031194\ttotal: 15.7s\tremaining: 9.9s\n",
      "92:\tlearn: 0.0031169\ttotal: 15.8s\tremaining: 9.71s\n",
      "93:\tlearn: 0.0031159\ttotal: 16s\tremaining: 9.53s\n",
      "94:\tlearn: 0.0031106\ttotal: 16.2s\tremaining: 9.36s\n",
      "95:\tlearn: 0.0031069\ttotal: 16.3s\tremaining: 9.19s\n",
      "96:\tlearn: 0.0031045\ttotal: 16.5s\tremaining: 9.01s\n",
      "97:\tlearn: 0.0030977\ttotal: 16.7s\tremaining: 8.84s\n",
      "98:\tlearn: 0.0030961\ttotal: 16.8s\tremaining: 8.66s\n",
      "99:\tlearn: 0.0030913\ttotal: 17s\tremaining: 8.49s\n",
      "100:\tlearn: 0.0030882\ttotal: 17.1s\tremaining: 8.32s\n",
      "101:\tlearn: 0.0030827\ttotal: 17.3s\tremaining: 8.16s\n",
      "102:\tlearn: 0.0030814\ttotal: 17.5s\tremaining: 7.97s\n",
      "103:\tlearn: 0.0030755\ttotal: 17.6s\tremaining: 7.81s\n",
      "104:\tlearn: 0.0030714\ttotal: 17.9s\tremaining: 7.65s\n",
      "105:\tlearn: 0.0030698\ttotal: 18s\tremaining: 7.47s\n",
      "106:\tlearn: 0.0030651\ttotal: 18.2s\tremaining: 7.3s\n",
      "107:\tlearn: 0.0030598\ttotal: 18.4s\tremaining: 7.14s\n",
      "108:\tlearn: 0.0030597\ttotal: 18.5s\tremaining: 6.96s\n",
      "109:\tlearn: 0.0030553\ttotal: 18.7s\tremaining: 6.79s\n",
      "110:\tlearn: 0.0030518\ttotal: 18.8s\tremaining: 6.62s\n",
      "111:\tlearn: 0.0030515\ttotal: 19s\tremaining: 6.45s\n",
      "112:\tlearn: 0.0030479\ttotal: 19.2s\tremaining: 6.28s\n",
      "113:\tlearn: 0.0030464\ttotal: 19.3s\tremaining: 6.1s\n",
      "114:\tlearn: 0.0030435\ttotal: 19.5s\tremaining: 5.93s\n",
      "115:\tlearn: 0.0030421\ttotal: 19.6s\tremaining: 5.75s\n",
      "116:\tlearn: 0.0030401\ttotal: 19.8s\tremaining: 5.58s\n",
      "117:\tlearn: 0.0030378\ttotal: 20s\tremaining: 5.41s\n",
      "118:\tlearn: 0.0030361\ttotal: 20.1s\tremaining: 5.24s\n",
      "119:\tlearn: 0.0030352\ttotal: 20.3s\tremaining: 5.07s\n",
      "120:\tlearn: 0.0030351\ttotal: 20.4s\tremaining: 4.89s\n",
      "121:\tlearn: 0.0030317\ttotal: 20.6s\tremaining: 4.72s\n",
      "122:\tlearn: 0.0030306\ttotal: 20.7s\tremaining: 4.55s\n",
      "123:\tlearn: 0.0030292\ttotal: 20.9s\tremaining: 4.38s\n",
      "124:\tlearn: 0.0030258\ttotal: 21s\tremaining: 4.21s\n",
      "125:\tlearn: 0.0030235\ttotal: 21.2s\tremaining: 4.04s\n",
      "126:\tlearn: 0.0030204\ttotal: 21.4s\tremaining: 3.87s\n",
      "127:\tlearn: 0.0030130\ttotal: 21.5s\tremaining: 3.7s\n",
      "128:\tlearn: 0.0030118\ttotal: 21.7s\tremaining: 3.53s\n",
      "129:\tlearn: 0.0030070\ttotal: 21.9s\tremaining: 3.37s\n",
      "130:\tlearn: 0.0030044\ttotal: 22.1s\tremaining: 3.2s\n",
      "131:\tlearn: 0.0030003\ttotal: 22.2s\tremaining: 3.03s\n",
      "132:\tlearn: 0.0029991\ttotal: 22.4s\tremaining: 2.86s\n",
      "133:\tlearn: 0.0029989\ttotal: 22.5s\tremaining: 2.69s\n",
      "134:\tlearn: 0.0029940\ttotal: 22.7s\tremaining: 2.52s\n",
      "135:\tlearn: 0.0029913\ttotal: 22.9s\tremaining: 2.36s\n",
      "136:\tlearn: 0.0029871\ttotal: 23.1s\tremaining: 2.19s\n",
      "137:\tlearn: 0.0029865\ttotal: 23.2s\tremaining: 2.02s\n",
      "138:\tlearn: 0.0029864\ttotal: 23.4s\tremaining: 1.85s\n",
      "139:\tlearn: 0.0029856\ttotal: 23.5s\tremaining: 1.68s\n",
      "140:\tlearn: 0.0029813\ttotal: 23.7s\tremaining: 1.51s\n",
      "141:\tlearn: 0.0029810\ttotal: 23.9s\tremaining: 1.34s\n",
      "142:\tlearn: 0.0029808\ttotal: 24s\tremaining: 1.18s\n",
      "143:\tlearn: 0.0029794\ttotal: 24.2s\tremaining: 1.01s\n",
      "144:\tlearn: 0.0029758\ttotal: 24.4s\tremaining: 840ms\n",
      "145:\tlearn: 0.0029730\ttotal: 24.5s\tremaining: 672ms\n",
      "146:\tlearn: 0.0029708\ttotal: 24.7s\tremaining: 503ms\n",
      "147:\tlearn: 0.0029676\ttotal: 24.8s\tremaining: 336ms\n",
      "148:\tlearn: 0.0029663\ttotal: 25s\tremaining: 168ms\n",
      "149:\tlearn: 0.0029655\ttotal: 25.2s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f452546c828>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#进行训练，使用catboost算法\n",
    "def train(df_dataset, iteration, model_path):\n",
    "    train_data = df_dataset.copy()\n",
    "    train_data.pop(\"buy_label\")\n",
    "    train_data.pop(\"user_id\")\n",
    "    train_data.pop(\"sku_id\")\n",
    "    print(len(train_data.columns.tolist()))\n",
    "    \n",
    "    cat_feature_list = [\"cate\", \"brand\", \"age\", \"sex\", \"a1\", \"a2\", \"a3\"]\n",
    "    cat_feature_list = [feat for feat in cat_feature_list if feat in train_data.columns.tolist()]\n",
    "    \n",
    "    train_label = df_dataset.loc[:, \"buy_label\"].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    model = CatBoostClassifier(iterations=iteration, \\\n",
    "                               loss_function=\"Logloss\", \\\n",
    "#                                learning_rate=1, \\\n",
    "                               task_type=\"GPU\", \\\n",
    "                              depth=6, \\\n",
    "                              leaf_estimation_method=\"Newton\", \\\n",
    "                               one_hot_max_size=2)\n",
    "    model.fit(train_data, train_label, cat_features=cat_feature_list)\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    return model\n",
    "\n",
    "# print(df_dataset.loc[:, \"buy_label\"])\n",
    "train(df_train_dataset, 150, \"model.cb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试打分\n",
    "def get_test_score(test_result):\n",
    "    \"\"\"\n",
    "    test_result is a DataFrame with columns: user_id, sku_id, buy_label, predict_label\n",
    "    \"\"\"\n",
    "    df_check_user_id = test_result.groupby(\"user_id\").sum().reset_index()\n",
    "    user_tp_cnt = len(df_check_user_id.loc[(df_check_user_id.loc[:, \"buy_label\"]>0) & (df_check_user_id.loc[:, \"predict_label\"]>0)])\n",
    "    user_fp_cnt = len(df_check_user_id.loc[(df_check_user_id.loc[:, \"buy_label\"]==0) & (df_check_user_id.loc[:, \"predict_label\"]>0)])\n",
    "    user_fn_cnt = len(df_check_user_id.loc[(df_check_user_id.loc[:, \"buy_label\"]>0) & (df_check_user_id.loc[:, \"predict_label\"]==0)])\n",
    "    user_tn_cnt = len(df_check_user_id.loc[(df_check_user_id.loc[:, \"buy_label\"]==0) & (df_check_user_id.loc[:, \"predict_label\"]==0)])\n",
    "    user_precise = user_tp_cnt/(user_tp_cnt+user_fp_cnt)\n",
    "    user_recall = user_tp_cnt/(user_tp_cnt+user_fn_cnt)\n",
    "    f11 = 6*user_recall*user_precise/(5*user_recall + user_precise)\n",
    "    \n",
    "    sku_tp_cnt = len(test_result.loc[(test_result.loc[:, \"buy_label\"]>0) & (test_result.loc[:, \"predict_label\"]>0)])\n",
    "    sku_fp_cnt = len(test_result.loc[(test_result.loc[:, \"buy_label\"]==0) & (test_result.loc[:, \"predict_label\"]>0)])\n",
    "    sku_fn_cnt = len(test_result.loc[(test_result.loc[:, \"buy_label\"]>0) & (test_result.loc[:, \"predict_label\"]==0)])\n",
    "    sku_tn_cnt = len(test_result.loc[(test_result.loc[:, \"buy_label\"]==0) & (test_result.loc[:, \"predict_label\"]==0)])\n",
    "    sku_precise = sku_tp_cnt/(sku_tp_cnt+sku_fp_cnt)\n",
    "    sku_recall = sku_tp_cnt/(sku_tp_cnt+sku_fn_cnt)\n",
    "    f12 = 5*sku_recall*sku_precise/(2*sku_recall + 3*sku_precise)\n",
    "    \n",
    "    print(\"user_tp_cnt\", user_tp_cnt)\n",
    "    print(\"user_fp_cnt\", user_fp_cnt)\n",
    "    print(\"user_fn_cnt\", user_fn_cnt)\n",
    "    print(\"user_tn_cnt\", user_tn_cnt)\n",
    "    print(\"user_precise\", user_precise)\n",
    "    print(\"user_recall\", user_recall)\n",
    "    print(\"f11\", f11)\n",
    "    \n",
    "    print(\"sku_tp_cnt\", sku_tp_cnt)\n",
    "    print(\"sku_fp_cnt\", sku_fp_cnt)\n",
    "    print(\"sku_fn_cnt\", sku_fn_cnt)\n",
    "    print(\"sku_tn_cnt\", sku_tn_cnt)\n",
    "    print(\"sku_precise\", sku_precise)\n",
    "    print(\"sku_recall\", sku_recall)\n",
    "    print(\"f12\", f12)\n",
    "    \n",
    "    score = 0.4*f11 + 0.6*f12\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score:  0.9981131468400417\n",
      "user_tp_cnt 758\n",
      "user_fp_cnt 580\n",
      "user_fn_cnt 219\n",
      "user_tn_cnt 17600\n",
      "user_precise 0.5665171898355755\n",
      "user_recall 0.7758444216990789\n",
      "f11 0.5931916003652015\n",
      "sku_tp_cnt 721\n",
      "sku_fp_cnt 720\n",
      "sku_fn_cnt 259\n",
      "sku_tn_cnt 252362\n",
      "sku_precise 0.5003469812630118\n",
      "sku_recall 0.7357142857142858\n",
      "f12 0.6192030230161457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.608798453955768"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#进行测试\n",
    "def test(df_dataset, model_path, threshold=0.5):\n",
    "    test_result = df_dataset.loc[:, [\"user_id\", \"sku_id\", \"buy_label\"]].reset_index()\n",
    "    test_data = df_dataset.copy()\n",
    "    test_data.pop(\"buy_label\")\n",
    "    test_data.pop(\"user_id\")\n",
    "    test_data.pop(\"sku_id\")\n",
    "    \n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "#     predict_label = model.predict(test_data)\n",
    "    predict_prob = model.predict(test_data, prediction_type='Probability')\n",
    "    predict_prob = predict_prob.T[1].T\n",
    "    predict_label = [prob > threshold for prob in predict_prob]\n",
    "    \n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(test_result.loc[:, \"buy_label\"].values.tolist(), predict_prob)\n",
    "\n",
    "    line = \"\"\n",
    "    for i in range(len(thresholds)):\n",
    "        line += str(fpr[i])+\"\\t\"+str(tpr[i])+\"\\t\"+str(thresholds[i])+\"\\n\"\n",
    "    f = open(\"roc_curve\", \"w\")\n",
    "    f.write(line)\n",
    "    f.close()\n",
    "    \n",
    "    auc_score = sklearn.metrics.roc_auc_score(test_result.loc[:, \"buy_label\"].values.tolist(), predict_prob)\n",
    "    print(\"auc_score: \", auc_score)\n",
    "    \n",
    "    test_result.loc[:, \"predict_label\"] = pd.Series(predict_label).T.astype(np.int32)\n",
    "\n",
    "    score = get_test_score(test_result)\n",
    "    \n",
    "    return score\n",
    "\n",
    "test(df_test_dataset, \"model.cb\", 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## train and test using xgboost ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于xgboost不原生支持类别特征，将类别特征转换为 OneHot 编码\n",
    "def one_hot_dataset(df_dataset):\n",
    "    cat_feature_list = [\"cate\", \"brand\", \"age\", \"sex\", \"a1\", \"a2\", \"a3\"]\n",
    "    cat_feature_list = [feat for feat in cat_feature_list if feat in df_dataset.columns.tolist()]\n",
    "    df_one_hot_dataset = pd.get_dummies(df_dataset, columns=cat_feature_list)\n",
    "    return df_one_hot_dataset\n",
    "\n",
    "df_one_hot_dataset = one_hot_dataset(df_dataset)\n",
    "# print(df_one_hot_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot_train_dataset, df_ont_hot_test_dataset = get_train_test_dataset(df_one_hot_dataset, 254062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "[0]\ttrain-logloss:0.438513\n",
      "[1]\ttrain-logloss:0.297849\n",
      "[2]\ttrain-logloss:0.209219\n",
      "[3]\ttrain-logloss:0.14993\n",
      "[4]\ttrain-logloss:0.108886\n",
      "[5]\ttrain-logloss:0.079877\n",
      "[6]\ttrain-logloss:0.059077\n",
      "[7]\ttrain-logloss:0.044042\n",
      "[8]\ttrain-logloss:0.033084\n",
      "[9]\ttrain-logloss:0.025044\n",
      "[10]\ttrain-logloss:0.019156\n",
      "[11]\ttrain-logloss:0.014819\n",
      "[12]\ttrain-logloss:0.0116\n",
      "[13]\ttrain-logloss:0.009206\n",
      "[14]\ttrain-logloss:0.007447\n",
      "[15]\ttrain-logloss:0.006128\n",
      "[16]\ttrain-logloss:0.005154\n",
      "[17]\ttrain-logloss:0.004428\n",
      "[18]\ttrain-logloss:0.003882\n",
      "[19]\ttrain-logloss:0.003454\n",
      "[20]\ttrain-logloss:0.003132\n",
      "[21]\ttrain-logloss:0.0029\n",
      "[22]\ttrain-logloss:0.002719\n",
      "[23]\ttrain-logloss:0.002595\n",
      "[24]\ttrain-logloss:0.002488\n",
      "[25]\ttrain-logloss:0.002394\n",
      "[26]\ttrain-logloss:0.002342\n",
      "[27]\ttrain-logloss:0.002258\n",
      "[28]\ttrain-logloss:0.002185\n",
      "[29]\ttrain-logloss:0.002126\n",
      "[30]\ttrain-logloss:0.002104\n",
      "[31]\ttrain-logloss:0.002063\n",
      "[32]\ttrain-logloss:0.002031\n",
      "[33]\ttrain-logloss:0.001975\n",
      "[34]\ttrain-logloss:0.001927\n",
      "[35]\ttrain-logloss:0.00191\n",
      "[36]\ttrain-logloss:0.001891\n",
      "[37]\ttrain-logloss:0.001853\n",
      "[38]\ttrain-logloss:0.001815\n",
      "[39]\ttrain-logloss:0.001796\n",
      "[40]\ttrain-logloss:0.001767\n",
      "[41]\ttrain-logloss:0.001738\n",
      "[42]\ttrain-logloss:0.001674\n",
      "[43]\ttrain-logloss:0.001646\n",
      "[44]\ttrain-logloss:0.00161\n",
      "[45]\ttrain-logloss:0.001583\n",
      "[46]\ttrain-logloss:0.001533\n",
      "[47]\ttrain-logloss:0.00151\n",
      "[48]\ttrain-logloss:0.00149\n",
      "[49]\ttrain-logloss:0.001466\n",
      "[50]\ttrain-logloss:0.001417\n",
      "[51]\ttrain-logloss:0.001402\n",
      "[52]\ttrain-logloss:0.001353\n",
      "[53]\ttrain-logloss:0.001326\n",
      "[54]\ttrain-logloss:0.001318\n",
      "[55]\ttrain-logloss:0.001293\n",
      "[56]\ttrain-logloss:0.001289\n",
      "[57]\ttrain-logloss:0.001252\n",
      "[58]\ttrain-logloss:0.001229\n",
      "[59]\ttrain-logloss:0.001221\n",
      "[60]\ttrain-logloss:0.001185\n",
      "[61]\ttrain-logloss:0.001167\n",
      "[62]\ttrain-logloss:0.001127\n",
      "[63]\ttrain-logloss:0.001081\n",
      "[64]\ttrain-logloss:0.00106\n",
      "[65]\ttrain-logloss:0.001044\n",
      "[66]\ttrain-logloss:0.001018\n",
      "[67]\ttrain-logloss:0.000989\n",
      "[68]\ttrain-logloss:0.000979\n",
      "[69]\ttrain-logloss:0.000952\n",
      "[70]\ttrain-logloss:0.000936\n",
      "[71]\ttrain-logloss:0.000911\n",
      "[72]\ttrain-logloss:0.000886\n",
      "[73]\ttrain-logloss:0.000878\n",
      "[74]\ttrain-logloss:0.000867\n",
      "[75]\ttrain-logloss:0.000841\n",
      "[76]\ttrain-logloss:0.000834\n",
      "[77]\ttrain-logloss:0.000804\n",
      "[78]\ttrain-logloss:0.000782\n",
      "[79]\ttrain-logloss:0.000772\n",
      "[80]\ttrain-logloss:0.00076\n",
      "[81]\ttrain-logloss:0.000757\n",
      "[82]\ttrain-logloss:0.000739\n",
      "[83]\ttrain-logloss:0.000735\n",
      "[84]\ttrain-logloss:0.000718\n",
      "[85]\ttrain-logloss:0.000714\n",
      "[86]\ttrain-logloss:0.000711\n",
      "[87]\ttrain-logloss:0.000691\n",
      "[88]\ttrain-logloss:0.000677\n",
      "[89]\ttrain-logloss:0.000665\n",
      "[90]\ttrain-logloss:0.000645\n",
      "[91]\ttrain-logloss:0.000639\n",
      "[92]\ttrain-logloss:0.000631\n",
      "[93]\ttrain-logloss:0.000613\n",
      "[94]\ttrain-logloss:0.000605\n",
      "[95]\ttrain-logloss:0.000595\n",
      "[96]\ttrain-logloss:0.000578\n",
      "[97]\ttrain-logloss:0.000569\n",
      "[98]\ttrain-logloss:0.000553\n",
      "[99]\ttrain-logloss:0.000549\n",
      "[100]\ttrain-logloss:0.000534\n",
      "[101]\ttrain-logloss:0.00053\n",
      "[102]\ttrain-logloss:0.000517\n",
      "[103]\ttrain-logloss:0.000512\n",
      "[104]\ttrain-logloss:0.000507\n",
      "[105]\ttrain-logloss:0.000501\n",
      "[106]\ttrain-logloss:0.000486\n",
      "[107]\ttrain-logloss:0.00047\n",
      "[108]\ttrain-logloss:0.000468\n",
      "[109]\ttrain-logloss:0.000457\n",
      "[110]\ttrain-logloss:0.000452\n",
      "[111]\ttrain-logloss:0.000447\n",
      "[112]\ttrain-logloss:0.000443\n",
      "[113]\ttrain-logloss:0.000442\n",
      "[114]\ttrain-logloss:0.000435\n",
      "[115]\ttrain-logloss:0.000423\n",
      "[116]\ttrain-logloss:0.000416\n",
      "[117]\ttrain-logloss:0.000407\n",
      "[118]\ttrain-logloss:0.000398\n",
      "[119]\ttrain-logloss:0.000393\n",
      "[120]\ttrain-logloss:0.000386\n",
      "[121]\ttrain-logloss:0.000379\n",
      "[122]\ttrain-logloss:0.000376\n",
      "[123]\ttrain-logloss:0.000368\n",
      "[124]\ttrain-logloss:0.000363\n",
      "[125]\ttrain-logloss:0.000358\n",
      "[126]\ttrain-logloss:0.000356\n",
      "[127]\ttrain-logloss:0.000348\n",
      "[128]\ttrain-logloss:0.000339\n",
      "[129]\ttrain-logloss:0.000334\n",
      "[130]\ttrain-logloss:0.000332\n",
      "[131]\ttrain-logloss:0.000326\n",
      "[132]\ttrain-logloss:0.000321\n",
      "[133]\ttrain-logloss:0.000318\n",
      "[134]\ttrain-logloss:0.000314\n",
      "[135]\ttrain-logloss:0.000309\n",
      "[136]\ttrain-logloss:0.000305\n",
      "[137]\ttrain-logloss:0.000302\n",
      "[138]\ttrain-logloss:0.000298\n",
      "[139]\ttrain-logloss:0.000295\n",
      "[140]\ttrain-logloss:0.000289\n",
      "[141]\ttrain-logloss:0.000285\n",
      "[142]\ttrain-logloss:0.000283\n",
      "[143]\ttrain-logloss:0.000281\n",
      "[144]\ttrain-logloss:0.000277\n",
      "[145]\ttrain-logloss:0.000274\n",
      "[146]\ttrain-logloss:0.000268\n",
      "[147]\ttrain-logloss:0.000264\n",
      "[148]\ttrain-logloss:0.000257\n",
      "[149]\ttrain-logloss:0.000251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x7f1eccdfdac8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xgb_train(df_dataset, model_path):\n",
    "    train_data = df_dataset.copy() # train_data 是训练集特征数据\n",
    "    train_data.pop(\"buy_label\") # 特征数据不包含标签，删除数据标签\n",
    "    train_data.pop(\"user_id\") # 用户id不应该作为特征\n",
    "    train_data.pop(\"sku_id\") # 商品id不应该作为特征\n",
    "    print(len(train_data.columns.tolist()))\n",
    "    \n",
    "    # train_label 是训练集的数据标签\n",
    "    train_label = df_dataset.loc[:, \"buy_label\"].apply(lambda x:1 if x else 0)\n",
    "    \n",
    "    # 将Pandas格式的特征及标签转换为xgboost的数据格式\n",
    "    dtrain = xgb.DMatrix(train_data, label=train_label)\n",
    "    \n",
    "    # 设置模型参数\n",
    "    xgb_param = {#学习速率\n",
    "                 \"learning_rate\":0.3, \\\n",
    "                 #预剪枝机制，限制模型复杂度\n",
    "                 \"gamma\":0.6, \\\n",
    "                 #每棵树的最大深度\n",
    "                 \"max_depth\":6, \\\n",
    "                 #L2损失的权重，防止过拟合\n",
    "                 \"lambda\":1, \\\n",
    "                 #树构建方法\n",
    "                 \"tree_method\":\"gpu_hist\", \\\n",
    "                 #正样本权重，因为我们的类别不平衡，令正样本的权重大于一\n",
    "                 \"scale_pos_weight\":1, \\\n",
    "                 #预测算法使用CPU还是GPU\n",
    "                 \"predictor\":\"gpu_predictor\", \\\n",
    "                 #目标函数选择（二分类问题使用逻辑回归的目标函数）\n",
    "                 \"objective\":\"binary:logistic\", \\\n",
    "                 \"eval_metric\":\"logloss\"}\n",
    "    \n",
    "    # 使用设定的参数及数据进行训练\n",
    "    xgb_model = xgb.train(xgb_param, dtrain, num_boost_round=150, evals=[(dtrain, \"train\")])\n",
    "    \n",
    "    # 保存训练好的模型到指定的路径\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(xgb_model, f)\n",
    "    return xgb_model\n",
    "\n",
    "# 输入经过独热编码处理后的数据，调用训练函数进行训练\n",
    "xgb_train(df_one_hot_train_dataset, \"xgb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score:  0.9979732873543123\n",
      "user_tp_cnt 794\n",
      "user_fp_cnt 673\n",
      "user_fn_cnt 183\n",
      "user_tn_cnt 17507\n",
      "user_precise 0.5412406271301977\n",
      "user_recall 0.812691914022518\n",
      "f11 0.5731472569778633\n",
      "sku_tp_cnt 760\n",
      "sku_fp_cnt 885\n",
      "sku_fn_cnt 220\n",
      "sku_tn_cnt 252197\n",
      "sku_precise 0.46200607902735563\n",
      "sku_recall 0.7755102040816326\n",
      "f12 0.6099518459069021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5952300103352866"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xgb_test(df_dataset, model_path, threshold=0.5):\n",
    "    test_result = df_dataset.loc[:, [\"user_id\", \"sku_id\", \"buy_label\"]].reset_index()\n",
    "    test_data = df_dataset.copy() #test_data 是验证集特征数据\n",
    "    test_data.pop(\"buy_label\") # 将验证集特征数据中的标签删掉\n",
    "    test_data.pop(\"user_id\") # 将验证集中的用户id删掉\n",
    "    test_data.pop(\"sku_id\") # 将验证集中的商品id删掉\n",
    "    #将Pandas格式的验证集的特征数据转换为xgboost的数据格式\n",
    "    dtest = xgb.DMatrix(test_data) \n",
    "    \n",
    "    #提取用户是否购买的标签，后面与预测结果对比，得到相关评价指标\n",
    "    test_label = test_result.loc[:, \"buy_label\"].values.tolist()\n",
    "    \n",
    "    #从磁盘中读取训练好的模型\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        xgb_model = pickle.load(f)\n",
    "    \n",
    "    #利用训练好的模型进行预测，得到分类为正样本的概率值\n",
    "    predict_score = xgb_model.predict(dtest)\n",
    "    #根据设定好的概率阈值得到预测标签\n",
    "    predict_label = [score>threshold for score in predict_score]\n",
    "    \n",
    "    #利用scikit-learn库中的函数，输入验证集真实标签和预测为正样本的概率，得到ROC曲线的数据\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(test_label, predict_score)\n",
    "    #保存ROC曲线的数据，可导出到excel中绘制ROC曲线\n",
    "    f = open(\"roc_curve\", \"w\")\n",
    "    line = \"\"\n",
    "    for i in range(len(thresholds)):\n",
    "        line += str(fpr[i])+\"\\t\"+str(tpr[i])+\"\\t\"+str(thresholds[i])+\"\\n\"\n",
    "    f.write(line)\n",
    "    f.close()\n",
    "    \n",
    "    #利用scikit-learn库中的函数，输入验证集真实标签和预测为正样本的概率，得到AUC值\n",
    "    auc_score = sklearn.metrics.roc_auc_score(test_label, predict_score)\n",
    "    print(\"auc_score: \", auc_score)\n",
    "    \n",
    "    #将预测标签附加到test_result中，计算F值\n",
    "    test_result.loc[:, \"predict_label\"] = pd.Series(predict_label).T.astype(np.int32)\n",
    "    score = get_test_score(test_result)\n",
    "    \n",
    "    return score\n",
    "\n",
    "xgb_test(df_ont_hot_test_dataset, \"xgb_model\", 0.165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### 利用catboost对特征重要性进行排序 ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 df 转换成 catboost 里面的 pool\n",
    "def df2pool(df_dataset):\n",
    "    data = df_dataset.copy()\n",
    "    data.pop(\"buy_label\")\n",
    "    data.pop(\"user_id\")\n",
    "    data.pop(\"sku_id\")\n",
    "    \n",
    "    cat_feature_list = [\"cate\", \"brand\", \"age\", \"sex\", \"a1\", \"a2\", \"a3\"]\n",
    "    cat_feature_list = [feat for feat in cat_feature_list if feat in data.columns.tolist()]\n",
    "    \n",
    "    label = df_dataset.loc[:, \"buy_label\"].apply(lambda x: 1 if x else 0)\n",
    "    \n",
    "    data_pool = cb.Pool(data, label, cat_features=cat_feature_list)\n",
    "    \n",
    "    return data_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, df_dataset):\n",
    "    train_data = df_dataset.copy()\n",
    "    train_data.pop(\"buy_label\")\n",
    "    train_data.pop(\"user_id\")\n",
    "    train_data.pop(\"sku_id\")\n",
    "    \n",
    "    cat_feature_list = [\"cate\", \"brand\", \"age\", \"sex\", \"a1\", \"a2\", \"a3\"]\n",
    "    cat_feature_list = [feat for feat in cat_feature_list if feat in train_data.columns.tolist()]\n",
    "    \n",
    "    train_label = df_dataset.loc[:, \"buy_label\"].apply(lambda x: 1 if x else 0)\n",
    "    \n",
    "    data_pool = cb.Pool(train_data, train_label, cat_features=cat_feature_list)\n",
    "    \n",
    "    feature_list = train_data.columns.tolist()\n",
    "    feature_importance = model.get_feature_importance(data_pool, type=\"FeatureImportance\")\n",
    "    feature_importance_list = []\n",
    "    for i in range(len(feature_list)):\n",
    "        feature_importance_list.append((feature_list[i], feature_importance[i]))\n",
    "    \n",
    "    \n",
    "    return feature_importance_list\n",
    "\n",
    "# with open(\"model.cb\", \"rb\") as f:\n",
    "#     model = pickle.load(f)\n",
    "# feature_importance_list = get_feature_importance(model, df_train_dataset)\n",
    "# fun = lambda x:-x[1]\n",
    "# sorted_feature = sorted(feature_importance_list, key=fun)\n",
    "# for f, ipt in sorted_feature:\n",
    "#     print(f, \" : \", ipt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到待删除的特征\n",
    "def features_to_pop(feature_importance_list):\n",
    "    feat_pop = []\n",
    "    for f, v in feature_importance_list:\n",
    "        if v < 1e-3:\n",
    "            feat_pop.append(f)\n",
    "    return feat_pop\n",
    "\n",
    "feat_pop = features_to_pop(feature_importance_list)\n",
    "len(feat_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得删除不重要特征的数据集\n",
    "def get_feature_poped_dataset(df_dataset, feat_pop):\n",
    "    for feat in feat_pop:\n",
    "        df_dataset.pop(feat)\n",
    "    return df_dataset\n",
    "    \n",
    "# df_feature_poped_dataset = get_feature_poped_dataset(df_dataset, feat_pop)\n",
    "# print(df_feature_poped_dataset.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dataset, df_test_dataset = get_train_test_dataset(df_feature_poped_dataset, 254062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(df_train_dataset, 10000, \"model.cb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(df_test_dataset, \"model.cb\", 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_curve(df_test_dataset, model_path):\n",
    "    data_pool = df2pool(df_test_dataset)\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return cb.utils.get_roc_curve(model, data_pool)\n",
    "\n",
    "fpr, tpr, thresholds = get_roc_curve(df_test_dataset, \"model.cb\")\n",
    "\n",
    "f = open(\"roc_curve\", \"w\")\n",
    "for i in range(len(thresholds)):\n",
    "    f.write(str(fpr[i]) + \"\\t\" + str(tpr[i]) + \"\\t\" + str(thresholds[i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/mnt/group/face/liulinyun/lch\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
